{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8adc370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"app/model\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e536e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Preprocessing tabular data...\n",
      "ğŸ”§ TF-IDF vectorization...\n",
      "ğŸš€ Building models...\n",
      "ğŸ§  Training stacking model...\n",
      "\n",
      "ğŸ“Š Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       453\n",
      "           1       0.99      0.98      0.99       453\n",
      "\n",
      "    accuracy                           0.99       906\n",
      "   macro avg       0.99      0.99      0.99       906\n",
      "weighted avg       0.99      0.99      0.99       906\n",
      "\n",
      "âœ… Accuracy: 0.9867549668874173\n",
      "\n",
      "ğŸ’¾ Saving models...\n",
      "âœ… Models saved to 'app/model/'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# ğŸ“¥ Load data\n",
    "data = pd.read_csv(\"../data/processed/balanced_data.csv\")\n",
    "X = data.drop(\"fraudulent\", axis=1)\n",
    "y = data[\"fraudulent\"]\n",
    "\n",
    "# ğŸ§ª Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ğŸ” Identify columns\n",
    "possible_text_cols = ['description', 'company_profile', 'requirements', 'benefits']\n",
    "text_cols = [col for col in possible_text_cols if col in X.columns]\n",
    "non_text_cols = [col for col in X.columns if col not in text_cols]\n",
    "\n",
    "# Numeric and Categorical\n",
    "numeric_cols = X_train[non_text_cols].select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X_train[non_text_cols].select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# ğŸ§¼ Pipelines\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, numeric_cols),\n",
    "    (\"cat\", cat_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# Fit transform on tabular data\n",
    "print(\"ğŸ”§ Preprocessing tabular data...\")\n",
    "X_train_tabular = preprocessor.fit_transform(X_train[non_text_cols])\n",
    "X_test_tabular = preprocessor.transform(X_test[non_text_cols])\n",
    "\n",
    "# ğŸ§  TF-IDF on text columns\n",
    "print(\"ğŸ”§ TF-IDF vectorization...\")\n",
    "text_vectors_train = []\n",
    "text_vectors_test = []\n",
    "tfidf_vectorizers = {}\n",
    "\n",
    "for col in text_cols:\n",
    "    tfidf = TfidfVectorizer(max_features=200)\n",
    "    vec_train = tfidf.fit_transform(X_train[col].fillna(\"\"))\n",
    "    vec_test = tfidf.transform(X_test[col].fillna(\"\"))\n",
    "    text_vectors_train.append(vec_train)\n",
    "    text_vectors_test.append(vec_test)\n",
    "    tfidf_vectorizers[col] = tfidf\n",
    "\n",
    "X_train_text = hstack(text_vectors_train)\n",
    "X_test_text = hstack(text_vectors_test)\n",
    "\n",
    "# ğŸ”— Final combined features\n",
    "X_train_final = hstack([csr_matrix(X_train_tabular), X_train_text])\n",
    "X_test_final = hstack([csr_matrix(X_test_tabular), X_test_text])\n",
    "\n",
    "# ğŸ¤– Base Models (Optimized for Speed)\n",
    "print(\"ğŸš€ Building models...\")\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=100, max_depth=4)\n",
    "cat = CatBoostClassifier(verbose=0, iterations=100, depth=4)\n",
    "\n",
    "# ğŸ”¼ Meta model\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# ğŸ¤ Stacking without passthrough\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=[('xgb', xgb), ('cat', cat)],\n",
    "    final_estimator=lr,\n",
    "    passthrough=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ğŸš€ Train\n",
    "print(\"ğŸ§  Training stacking model...\")\n",
    "stack_model.fit(X_train_final, y_train)\n",
    "\n",
    "# ğŸ§ª Evaluate\n",
    "print(\"\\nğŸ“Š Classification Report:\\n\")\n",
    "y_pred = stack_model.predict(X_test_final)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"âœ… Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# ğŸ’¾ Save models\n",
    "print(\"\\nğŸ’¾ Saving models...\")\n",
    "os.makedirs(\"app/model\", exist_ok=True)\n",
    "joblib.dump(stack_model, \"app/model/stacking_model.pkl\")\n",
    "joblib.dump(preprocessor, \"app/model/preprocessor.pkl\")\n",
    "joblib.dump(tfidf_vectorizers, \"app/model/tfidf_vectorizers.pkl\")\n",
    "print(\"âœ… Models saved to 'app/model/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17e66a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title', 'location', 'department', 'description', 'requirements', 'employment_type', 'required_experience', 'required_education', 'industry', 'function', 'all_text', 'textblob_polarity', 'vader_neg', 'vader_neu', 'vader_pos', 'vader_compound', 'keyword_money', 'keyword_earn', 'keyword_click', 'keyword_investment', 'keyword_urgent', 'keyword_opportunity', 'keyword_work from home']\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1123d704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['app/model/label_encoders.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the list of features used in training\n",
    "import json\n",
    "with open(\"app/model/features.json\", \"w\") as f:\n",
    "    json.dump(list(X_train.columns), f)\n",
    "\n",
    "# Save label encoders if any were used\n",
    "joblib.dump(label_encoders, \"app/model/label_encoders.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966bcfee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
